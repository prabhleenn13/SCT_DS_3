# ğŸš€ Decision Tree Classifier on Bank Marketing Dataset (Internship Task 3)

This repository contains my **internship Task 3 project**, where I built and evaluated a Decision Tree Classifier on the **Bank Marketing dataset** from the UCI Machine Learning Repository.  

The goal of this project is to predict whether a client will subscribe to a term deposit based on various personal, social, and economic attributes.  

---

## ğŸ“‚ Files in this repository

| File | Description |
|-------|-------------|
| `bank_marketing_decision_tree.ipynb` | Jupyter notebook containing the complete workflow: data loading, exploration, preprocessing, model training, evaluation, and visualization |
| `full_dataset_decision_tree.png` | Visualization of the decision tree trained on the entire dataset (max depth = 5) |


---

## âš™ï¸ How to use this project

### âœ… Requirements
- Jupyter Notebook / JupyterLab
- Python 3.x
- Libraries:
  - pandas
  - numpy
  - matplotlib
  - seaborn
  - scikit-learn
  - pydotplus
  - graphviz

### âœ… Steps to run
1ï¸âƒ£ **Clone this repository**
```bash
git clone https://github.com/YourUsername/decision-tree-internship.git
or download as a ZIP and extract.

2ï¸âƒ£ Get the dataset

Download the dataset from UCI Bank Marketing

Place bank-additional-full.csv in the same directory as the notebook (or update the path in the code).

3ï¸âƒ£ Launch Jupyter Notebook

bash
Copy code
jupyter notebook
Open bank_marketing_decision_tree.ipynb and run all cells.

ğŸ“Š Dataset Overview
The dataset contains information on direct marketing campaigns (phone calls) of a Portuguese banking institution.

Target:
y â€” Has the client subscribed to a term deposit? (yes/no)

ğŸ“ˆ Project highlights
âœ… One-hot encoding for categorical features
âœ… Decision Tree Classifier using entropy criterion
âœ… Train-test split (80% train / 20% test, stratified by target)
âœ… Evaluation: accuracy, confusion matrix, classification report
âœ… Visualizations: decision tree plots, top feature importances

ğŸ’¡ Possible future improvements
âœ¨ Hyperparameter tuning (e.g., GridSearchCV)
âœ¨ Apply cross-validation for better model reliability
âœ¨ Address class imbalance (e.g., SMOTE, class weights)
âœ¨ Compare performance with other models (e.g., Random Forest, Logistic Regression)
